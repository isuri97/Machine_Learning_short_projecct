{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Active Learning - Data Annotation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XNI5AVlyZyi",
        "outputId": "2e647f69-2c70-4b2d-c774-60139b90a95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfYraWV0y1xI"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTMScDVczRt1",
        "outputId": "ab424ac4-487f-4cb0-c28a-4e26e8fb433f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27dJ6uRazUMC"
      },
      "source": [
        "# Load the image dataset\n",
        "digits = datasets.load_digits()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6NEVDE3zfne"
      },
      "source": [
        "def get_initial_labelled_dataset(num_samples_per_class=5):\n",
        "  \"\"\"\n",
        "  Getting the initial balanced dataset. Although this is random in this code.\n",
        "  In actual production system it should be informative labelled dataset given by the annotators/SMEs.\n",
        "\n",
        "  Args:\n",
        "    num_samples_per_class: int, number of samples to be takes per class in the first iteration.\n",
        "\n",
        "  Returns:\n",
        "    numpy array of labelled dataset with true labels and pooled dataset with true labels (for performance checking)\n",
        "  \"\"\"\n",
        "\n",
        "  X = list()\n",
        "  y = list()\n",
        "  X_pooled = list()\n",
        "  y_pooled = list()\n",
        "  labelled_idx = list()\n",
        "\n",
        "  counter_dict = dict()\n",
        "\n",
        "  for idx, target in enumerate(digits['target']):\n",
        "    if target in counter_dict:\n",
        "      if counter_dict[target] == num_samples_per_class:\n",
        "        continue\n",
        "      counter_dict[target] += 1\n",
        "    else:\n",
        "      counter_dict[target] = 1\n",
        "    X.append(digits['data'][idx])\n",
        "    y.append(target)\n",
        "    labelled_idx.append(idx)\n",
        "\n",
        "  X_pooled = np.delete(digits['data'], labelled_idx, axis=0)\n",
        "  y_pooled = np.delete(digits['target'], labelled_idx)\n",
        "\n",
        "  return np.asarray(X), np.asarray(y), X_pooled, y_pooled"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28-PydInzkoL"
      },
      "source": [
        "X, y, X_pooled, y_pooled = get_initial_labelled_dataset()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky1qFaEP1FUq",
        "outputId": "d365d18c-d3c2-411a-9bc0-dcec2d262294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_pooled.shape)\n",
        "print(y_pooled.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 64)\n",
            "(50,)\n",
            "(1747, 64)\n",
            "(1747,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nExUpgJq4bb-"
      },
      "source": [
        "# Create Classification Model - Keras Model\n",
        "\n",
        "def create_model():\n",
        "  # Input Layer\n",
        "  input_layer = tf.keras.Input(shape=(64,), name='input_layer') # Feature dimension=64\n",
        "  input_dropout_layer = tf.keras.layers.Dropout(0.4, name='input_dropout_layer')(input_layer, training=True) #training=True activates MC Dropout\n",
        "\n",
        "  # Hidden Layer 1\n",
        "  dense_layer_1 = tf.keras.layers.Dense(256, activation='relu', name='dense_layer_1')(input_dropout_layer)\n",
        "  dropout_layer_1 = tf.keras.layers.Dropout(0.4, name='dropout_layer_1')(dense_layer_1, training=True)\n",
        "\n",
        "  # Hidden Layer 2\n",
        "  dense_layer_2 = tf.keras.layers.Dense(256, activation='relu', name='dense_layer_2')(dropout_layer_1)\n",
        "  dropout_layer_2 = tf.keras.layers.Dropout(0.4, name='dropout_layer_2')(dense_layer_2, training=True)\n",
        "\n",
        "  # Hidden Layer 3\n",
        "  dense_layer_3 = tf.keras.layers.Dense(256, activation='relu', name='dense_layer_3')(dropout_layer_2)\n",
        "  dropout_layer_3 = tf.keras.layers.Dropout(0.4, name='dropout_layer_3')(dense_layer_3, training=True)\n",
        "\n",
        "  # Output Layer\n",
        "  output_layer = tf.keras.layers.Dense(len(digits['target_names']), activation='softmax', name='output_layer')(dropout_layer_3)\n",
        "\n",
        "  # Model Init\n",
        "  model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='Model')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKIVNesd_kgG"
      },
      "source": [
        "def max_entropy_acquisition(X_pool, T, num_query):\n",
        "  \"\"\"\n",
        "  Calculate the entropy of the ensempe of models (by using MC Dropout).\n",
        "  Get the max entropy and return the index of the data\n",
        "\n",
        "  Args:\n",
        "    X_pool: ndarray, Pooled dataset (unlabelled)\n",
        "    T: int, number of iteration to replicate ensemble model using MC Dropout\n",
        "    num_query: int, number of datapoints to be returned by the model per itration\n",
        "\n",
        "  Returns:\n",
        "    Index points of uncertain dataset\n",
        "    mean entropy value\n",
        "  \"\"\"\n",
        "\n",
        "  proba_all = np.zeros(shape=(X_pool.shape[0], 10))\n",
        "  for _ in range(T):\n",
        "    probas = model.predict(X_pool)\n",
        "    proba_all += probas\n",
        "  avg_proba = np.divide(proba_all, T)\n",
        "  entropy_avg = sp.stats.entropy(avg_proba, base=10, axis=1)\n",
        "  uncertain_idx = entropy_avg.argsort()[-num_query:][::-1]\n",
        "  return uncertain_idx, entropy_avg.mean()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yoshGsa_mtz"
      },
      "source": [
        "def manage_data(X, y, X_pooled, y_pooled, idx):\n",
        "  \"\"\"\n",
        "  After every iteration, the uncertain unlabelled data will be given the true labels (in reality the manual annotator will label the data)\n",
        "\n",
        "  Args:\n",
        "    X: ndarray, Training Features\n",
        "    y: ndarray, Training Labels (true)\n",
        "    X_pooled: ndarray, Unlabelled dataset\n",
        "    y_pooled: ndarray, True labels of the unlabelled dataset\n",
        "    idx: ndarray,list, uncertain data index\n",
        "\n",
        "  Returns:\n",
        "    Lablled and unlabelled dataset\n",
        "  \"\"\"\n",
        "\n",
        "  pool_mask = np.ones(len(X_pooled), dtype=bool)\n",
        "  pool_mask[idx] = False\n",
        "  pool_mask_2 = np.zeros(len(X_pooled), dtype=bool)\n",
        "  pool_mask_2[idx] = True\n",
        "  new_training = X_pooled[pool_mask_2]\n",
        "  new_label = y_pooled[pool_mask_2]\n",
        "  X_pooled = X_pooled[pool_mask]\n",
        "  y_pooled = y_pooled[pool_mask]\n",
        "  X = np.concatenate([X, new_training])\n",
        "  y = np.concatenate([y, new_label])\n",
        "\n",
        "  return X, y, X_pooled, y_pooled"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgd51rSEJXlX",
        "outputId": "bbf9c337-fb88-427b-a8a2-84d89a8c9732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Main loop\n",
        "for i in range(30):\n",
        "  print('*'*50)\n",
        "  model = create_model()\n",
        "  custom_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "  model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
        "  model.fit(X, y, epochs=20, batch_size=8, verbose=0)\n",
        "  uncertain_idx, entropy_avg = max_entropy_acquisition(X_pooled, 100, 20)\n",
        "  print('Average Entropy: {}'.format(entropy_avg))\n",
        "  X, y, X_pooled, y_pooled = manage_data(X, y, X_pooled, y_pooled, uncertain_idx)\n",
        "  print('Iteration Done: {}'.format(i+1))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "Average Entropy: 0.6420101556084087\n",
            "Iteration Done: 1\n",
            "**************************************************\n",
            "Average Entropy: 0.6420311778681584\n",
            "Iteration Done: 2\n",
            "**************************************************\n",
            "Average Entropy: 0.648680279384038\n",
            "Iteration Done: 3\n",
            "**************************************************\n",
            "Average Entropy: 0.6228563044281832\n",
            "Iteration Done: 4\n",
            "**************************************************\n",
            "Average Entropy: 0.6006466136966667\n",
            "Iteration Done: 5\n",
            "**************************************************\n",
            "Average Entropy: 0.6076293644336954\n",
            "Iteration Done: 6\n",
            "**************************************************\n",
            "Average Entropy: 0.5876639253670166\n",
            "Iteration Done: 7\n",
            "**************************************************\n",
            "Average Entropy: 0.5709516567218181\n",
            "Iteration Done: 8\n",
            "**************************************************\n",
            "Average Entropy: 0.5843726451251753\n",
            "Iteration Done: 9\n",
            "**************************************************\n",
            "Average Entropy: 0.5462274581433955\n",
            "Iteration Done: 10\n",
            "**************************************************\n",
            "Average Entropy: 0.5696466252842279\n",
            "Iteration Done: 11\n",
            "**************************************************\n",
            "Average Entropy: 0.5474747601442954\n",
            "Iteration Done: 12\n",
            "**************************************************\n",
            "Average Entropy: 0.5611435304754988\n",
            "Iteration Done: 13\n",
            "**************************************************\n",
            "Average Entropy: 0.5340312954154328\n",
            "Iteration Done: 14\n",
            "**************************************************\n",
            "Average Entropy: 0.4982547994541683\n",
            "Iteration Done: 15\n",
            "**************************************************\n",
            "Average Entropy: 0.5189190497892808\n",
            "Iteration Done: 16\n",
            "**************************************************\n",
            "Average Entropy: 0.5160203299756823\n",
            "Iteration Done: 17\n",
            "**************************************************\n",
            "Average Entropy: 0.46950896918237994\n",
            "Iteration Done: 18\n",
            "**************************************************\n",
            "Average Entropy: 0.4564359613135137\n",
            "Iteration Done: 19\n",
            "**************************************************\n",
            "Average Entropy: 0.46709430692180237\n",
            "Iteration Done: 20\n",
            "**************************************************\n",
            "Average Entropy: 0.4693913559676681\n",
            "Iteration Done: 21\n",
            "**************************************************\n",
            "Average Entropy: 0.49022046409631764\n",
            "Iteration Done: 22\n",
            "**************************************************\n",
            "Average Entropy: 0.4492766031171844\n",
            "Iteration Done: 23\n",
            "**************************************************\n",
            "Average Entropy: 0.4559515834975229\n",
            "Iteration Done: 24\n",
            "**************************************************\n",
            "Average Entropy: 0.42342145634575196\n",
            "Iteration Done: 25\n",
            "**************************************************\n",
            "Average Entropy: 0.45567028629970907\n",
            "Iteration Done: 26\n",
            "**************************************************\n",
            "Average Entropy: 0.42636117085687764\n",
            "Iteration Done: 27\n",
            "**************************************************\n",
            "Average Entropy: 0.415559733162177\n",
            "Iteration Done: 28\n",
            "**************************************************\n",
            "Average Entropy: 0.371902259405915\n",
            "Iteration Done: 29\n",
            "**************************************************\n",
            "Average Entropy: 0.34570659859489655\n",
            "Iteration Done: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAa-mWIPMdFb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}